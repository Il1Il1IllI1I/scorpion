{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 엑셀 파일 로드\n",
    "kosdaq_delisted_file_path = '상장폐지기업사유(피흡수합병제외).xlsx'\n",
    "kosdaq_delisted_data = pd.read_excel(kosdaq_delisted_file_path)\n",
    "\n",
    "# CSV 파일 로드 (CP949 인코딩 사용)\n",
    "kosdaq_companies_file_path = '111.csv'\n",
    "kosdaq_companies_data = pd.read_csv(kosdaq_companies_file_path, encoding='CP949')\n",
    "\n",
    "# 데이터셋 A(상장폐지 기업)의 모든 종목코드가 데이터셋 B(전체 코스닥 기업)에 있는지 확인\n",
    "delisted_companies_codes = set(kosdaq_delisted_data['종목코드'])\n",
    "all_kosdaq_companies_codes = set(kosdaq_companies_data['거래소코드'])\n",
    "missing_companies_codes = delisted_companies_codes - all_kosdaq_companies_codes\n",
    "\n",
    "# 누락된 회사명 추출\n",
    "missing_companies_names = kosdaq_delisted_data[kosdaq_delisted_data['종목코드'].isin(missing_companies_codes)]['회사명']\n",
    "missing_companies_names_list = missing_companies_names.tolist()\n",
    "\n",
    "# 데이터셋 A에서 누락된 회사들 제거\n",
    "kosdaq_delisted_data_cleaned = kosdaq_delisted_data[~kosdaq_delisted_data['회사명'].isin(missing_companies_names_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5395\n",
      "1     111\n",
      "Name: 부도여부, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\성현태\\AppData\\Local\\Temp\\ipykernel_22660\\1364789009.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  kosdaq_delisted_data_cleaned['부도여부'] = 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 엑셀 파일 로드\n",
    "kosdaq_delisted_file_path = '상장폐지기업사유(피흡수합병제외).xlsx'\n",
    "kosdaq_delisted_data = pd.read_excel(kosdaq_delisted_file_path)\n",
    "\n",
    "# CSV 파일 로드 (CP949 인코딩 사용)\n",
    "kosdaq_companies_file_path = '111.csv'\n",
    "kosdaq_companies_data = pd.read_csv(kosdaq_companies_file_path, encoding='CP949')\n",
    "\n",
    "# 데이터셋 A(상장폐지 기업)의 모든 종목코드가 데이터셋 B(전체 코스닥 기업)에 있는지 확인\n",
    "delisted_companies_codes = set(kosdaq_delisted_data['종목코드'])\n",
    "all_kosdaq_companies_codes = set(kosdaq_companies_data['거래소코드'])\n",
    "missing_companies_codes = delisted_companies_codes - all_kosdaq_companies_codes\n",
    "\n",
    "# 누락된 회사명 추출\n",
    "missing_companies_names = kosdaq_delisted_data[kosdaq_delisted_data['종목코드'].isin(missing_companies_codes)]['회사명']\n",
    "missing_companies_names_list = missing_companies_names.tolist()\n",
    "\n",
    "# 데이터셋 A에서 누락된 회사들 제거\n",
    "kosdaq_delisted_data_cleaned = kosdaq_delisted_data[~kosdaq_delisted_data['회사명'].isin(missing_companies_names_list)]\n",
    "\n",
    "# kosdaq_companies_data에 있는 회사명을 0으로 레이블링\n",
    "kosdaq_companies_data['부도여부'] = 0\n",
    "\n",
    "# kosdaq_delisted_data_cleaned에 있는 회사명을 1로 레이블링\n",
    "kosdaq_delisted_data_cleaned['부도여부'] = 1\n",
    "\n",
    "# 두 데이터프레임을 병합\n",
    "combined_data = pd.concat([kosdaq_companies_data, kosdaq_delisted_data_cleaned], ignore_index=True)\n",
    "\n",
    "# 결과 확인\n",
    "print(combined_data['부도여부'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       실리콘화일\n",
       "1        CU전자\n",
       "2       아라온테크\n",
       "3        쌍용건설\n",
       "4      나노트로닉스\n",
       "        ...  \n",
       "128       제이콤\n",
       "129     엠엔에프씨\n",
       "130      대선조선\n",
       "131    스톰이앤에프\n",
       "132     중앙디자인\n",
       "Name: 회사명, Length: 111, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kosdaq_delisted_data_cleaned['회사명']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\성현태\\AppData\\Local\\Temp\\ipykernel_22660\\764920854.py:33: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
      "  top10_avg = kosdaq_companies_data.groupby('회계년도')[col].nlargest(10).mean(level=0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터셋 B (코스닥 전체 기업) 로드\n",
    "kosdaq_companies_file_path = '111.csv'\n",
    "kosdaq_companies_data = pd.read_csv(kosdaq_companies_file_path, encoding='CP949')\n",
    "\n",
    "# 데이터셋 A (상장폐지 기업) 로드 및 전처리\n",
    "kosdaq_delisted_file_path = '상장폐지기업사유(피흡수합병제외).xlsx'\n",
    "kosdaq_delisted_data = pd.read_excel(kosdaq_delisted_file_path)\n",
    "\n",
    "# 데이터셋 A의 결측치 제거 및 이상치 처리\n",
    "numeric_columns = kosdaq_delisted_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numeric_columns:\n",
    "    kosdaq_delisted_data[col] = winsorize(kosdaq_delisted_data[col], limits=[0.01, 0.01])  # 이상치 처리\n",
    "\n",
    "# 데이터셋 B의 재무비율 칼럼 식별 및 회계년도 형식 변환\n",
    "financial_ratios_columns = kosdaq_companies_data.columns.drop(['회사명', '거래소코드', '회계년도'])\n",
    "kosdaq_companies_data['회계년도'] = kosdaq_companies_data['회계년도'].str.split('/').str[0].astype(int)\n",
    "\n",
    "# 각 재무비율에 대해 파생변수 생성\n",
    "for col in financial_ratios_columns:\n",
    "    # 시차 차이 계산\n",
    "    kosdaq_companies_data[f'{col}_시차차이'] = kosdaq_companies_data.groupby('회사명')[col].diff()\n",
    "    # 시차 비율 계산\n",
    "    kosdaq_companies_data[f'{col}_시차비율'] = kosdaq_companies_data.groupby('회사명')[col].pct_change()\n",
    "    # 연도별 상위 10개 기업 평균과의 차이\n",
    "    top10_avg = kosdaq_companies_data.groupby('회계년도')[col].nlargest(10).mean(level=0)\n",
    "    kosdaq_companies_data = kosdaq_companies_data.join(top10_avg, on='회계년도', rsuffix='_상위10평균')\n",
    "    kosdaq_companies_data[f'{col}_상위10차이'] = kosdaq_companies_data[f'{col}_상위10평균'] - kosdaq_companies_data[col]\n",
    "    # 연도별 전체 평균과의 차이\n",
    "    overall_avg = kosdaq_companies_data.groupby('회계년도')[col].transform('mean')\n",
    "    kosdaq_companies_data[f'{col}_전체평균차이'] = overall_avg - kosdaq_companies_data[col]\n",
    "\n",
    "# 상위 10개 기업 평균 관련 열 제거\n",
    "top10_avg_columns = [col for col in kosdaq_companies_data.columns if '_상위10평균' in col]\n",
    "kosdaq_companies_data_cleaned = kosdaq_companies_data.drop(columns=top10_avg_columns)\n",
    "\n",
    "# 데이터셋 A와 B를 레이블링\n",
    "kosdaq_delisted_data_cleaned = kosdaq_delisted_data.copy()\n",
    "kosdaq_delisted_data_cleaned['부도여부'] = 1\n",
    "kosdaq_companies_data_cleaned['부도여부'] = 0\n",
    "\n",
    "# 데이터 병합\n",
    "combined_data = pd.concat([kosdaq_companies_data_cleaned, kosdaq_delisted_data_cleaned], ignore_index=True)\n",
    "\n",
    "# 독립변수(X)와 종속변수(y) 분리\n",
    "X = combined_data.drop(columns=['부도여부', '회사명', '거래소코드', '종목코드', '회계년도'])\n",
    "y = combined_data['부도여부']\n",
    "\n",
    "# 결측치를 0으로 대체\n",
    "X = X.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\성현태\\AppData\\Local\\Temp\\ipykernel_22660\\2822426184.py:33: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
      "  top10_avg = kosdaq_companies_data.groupby('회계년도')[col].nlargest(10).mean(level=0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5395, 5528]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22660\\2822426184.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m# SMOTE 적용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0msmote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;31m# 데이터 분할\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1162\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    408\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5395, 5528]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터셋 B (코스닥 전체 기업) 로드\n",
    "kosdaq_companies_file_path = '111.csv'\n",
    "kosdaq_companies_data = pd.read_csv(kosdaq_companies_file_path, encoding='CP949')\n",
    "\n",
    "# 데이터셋 A (상장폐지 기업) 로드 및 전처리\n",
    "kosdaq_delisted_file_path = '상장폐지기업사유(피흡수합병제외).xlsx'\n",
    "kosdaq_delisted_data = pd.read_excel(kosdaq_delisted_file_path)\n",
    "\n",
    "# 데이터셋 A의 결측치 제거 및 이상치 처리\n",
    "numeric_columns = kosdaq_delisted_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numeric_columns:\n",
    "    kosdaq_delisted_data[col] = winsorize(kosdaq_delisted_data[col], limits=[0.01, 0.01])  # 이상치 처리\n",
    "\n",
    "# 데이터셋 B의 재무비율 칼럼 식별 및 회계년도 형식 변환\n",
    "financial_ratios_columns = kosdaq_companies_data.columns.drop(['회사명', '거래소코드', '회계년도'])\n",
    "kosdaq_companies_data['회계년도'] = kosdaq_companies_data['회계년도'].str.split('/').str[0].astype(int)\n",
    "\n",
    "# 각 재무비율에 대해 파생변수 생성\n",
    "for col in financial_ratios_columns:\n",
    "    # 시차 차이 계산\n",
    "    kosdaq_companies_data[f'{col}_시차차이'] = kosdaq_companies_data.groupby('회사명')[col].diff()\n",
    "    # 시차 비율 계산\n",
    "    kosdaq_companies_data[f'{col}_시차비율'] = kosdaq_companies_data.groupby('회사명')[col].pct_change()\n",
    "    # 연도별 상위 10개 기업 평균과의 차이\n",
    "    top10_avg = kosdaq_companies_data.groupby('회계년도')[col].nlargest(10).mean(level=0)\n",
    "    kosdaq_companies_data = kosdaq_companies_data.join(top10_avg, on='회계년도', rsuffix='_상위10평균')\n",
    "    kosdaq_companies_data[f'{col}_상위10차이'] = kosdaq_companies_data[f'{col}_상위10평균'] - kosdaq_companies_data[col]\n",
    "    # 연도별 전체 평균과의 차이\n",
    "    overall_avg = kosdaq_companies_data.groupby('회계년도')[col].transform('mean')\n",
    "    kosdaq_companies_data[f'{col}_전체평균차이'] = overall_avg - kosdaq_companies_data[col]\n",
    "\n",
    "# 상위 10개 기업 평균 관련 열 제거\n",
    "top10_avg_columns = [col for col in kosdaq_companies_data.columns if '_상위10평균' in col]\n",
    "kosdaq_companies_data_cleaned = kosdaq_companies_data.drop(columns=top10_avg_columns)\n",
    "\n",
    "# 데이터셋 A와 B를 레이블링\n",
    "kosdaq_delisted_data_cleaned = kosdaq_delisted_data.copy()\n",
    "kosdaq_delisted_data_cleaned['부도여부'] = 1\n",
    "kosdaq_companies_data_cleaned['부도여부'] = 0\n",
    "\n",
    "# 데이터 병합\n",
    "combined_data = pd.concat([kosdaq_companies_data_cleaned, kosdaq_delisted_data_cleaned], ignore_index=True)\n",
    "\n",
    "financial_ratios_columns = ['매출액증가율(IFRS)', '총자본증가율(IFRS)', '매출액순이익률(IFRS)', '총자본정상영업이익률(IFRS)',\n",
    "                            'CASH FLOW 대 부채비율(IFRS)', 'CASH FLOW 대 총자본비율(IFRS)', '총자본회전률(IFRS)',\n",
    "                            '자기자본회전률(IFRS)', '총자본투자효율(IFRS)', '설비투자효율(IFRS)']\n",
    "X = kosdaq_companies_data_cleaned[financial_ratios_columns]\n",
    "\n",
    "y = combined_data['부도여부']\n",
    "\n",
    "\n",
    "# X 데이터프레임과 y 시리즈의 행 수를 맞추기 위해 y에 해당하는 행 삭제\n",
    "combined_data = pd.concat([kosdaq_companies_data_cleaned, kosdaq_delisted_data_cleaned], ignore_index=True)\n",
    "X = kosdaq_companies_data_cleaned[financial_ratios_columns]\n",
    "y = combined_data['부도여부']\n",
    "\n",
    "# 결측치를 0으로 대체\n",
    "# X = X.fillna(0)\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=0)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=0)\n",
    "\n",
    "# RandomForest 모델 생성 및 학습\n",
    "rf_classifier = RandomForestClassifier(random_state=0)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 모델 성능 평가\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 특성 중요도 분석 및 시각화\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "features = X_train.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "sorted_idx = feature_importance_df['Importance'].argsort()\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(feature_importances)), feature_importance_df['Importance'][sorted_idx], align='center')\n",
    "plt.yticks(range(len(feature_importances)), [features[i] for i in sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n",
    "\n",
    "# 모델 성능 보고서 출력\n",
    "print(\"Classification Report:\\n\", classification_report_result)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\성현태\\AppData\\Local\\Temp\\ipykernel_22660\\4196280188.py:29: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
      "  top10_avg = kosdaq_companies_data.groupby('회계년도')[col].nlargest(10).mean(level=0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# 데이터셋 B (코스닥 전체 기업) 로드\n",
    "kosdaq_companies_file_path = '111.csv'\n",
    "kosdaq_companies_data = pd.read_csv(kosdaq_companies_file_path, encoding='CP949')\n",
    "\n",
    "# 데이터셋 A (상장폐지 기업) 로드 및 전처리\n",
    "kosdaq_delisted_file_path = '상장폐지기업사유(피흡수합병제외).xlsx'\n",
    "kosdaq_delisted_data = pd.read_excel(kosdaq_delisted_file_path)\n",
    "\n",
    "# 데이터셋 A의 결측치 제거 및 이상치 처리\n",
    "\n",
    "numeric_columns = kosdaq_delisted_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numeric_columns:\n",
    "    kosdaq_delisted_data[col] = winsorize(kosdaq_delisted_data[col], limits=[0.01, 0.01])  # 이상치 처리\n",
    "\n",
    "# 데이터셋 B의 재무비율 칼럼 식별 및 회계년도 형식 변환\n",
    "financial_ratios_columns = kosdaq_companies_data.columns.drop(['회사명', '거래소코드', '회계년도'])\n",
    "kosdaq_companies_data['회계년도'] = kosdaq_companies_data['회계년도'].str.split('/').str[0].astype(int)\n",
    "\n",
    "# 각 재무비율에 대해 파생변수 생성\n",
    "for col in financial_ratios_columns:\n",
    "    # 시차 차이 계산\n",
    "    kosdaq_companies_data[f'{col}_시차차이'] = kosdaq_companies_data.groupby('회사명')[col].diff()\n",
    "    # 시차 비율 계산\n",
    "    kosdaq_companies_data[f'{col}_시차비율'] = kosdaq_companies_data.groupby('회사명')[col].pct_change()\n",
    "    # 연도별 상위 10개 기업 평균과의 차이\n",
    "    top10_avg = kosdaq_companies_data.groupby('회계년도')[col].nlargest(10).mean(level=0)\n",
    "    kosdaq_companies_data = kosdaq_companies_data.join(top10_avg, on='회계년도', rsuffix='_상위10평균')\n",
    "    kosdaq_companies_data[f'{col}_상위10차이'] = kosdaq_companies_data[f'{col}_상위10평균'] - kosdaq_companies_data[col]\n",
    "    # 연도별 전체 평균과의 차이\n",
    "    overall_avg = kosdaq_companies_data.groupby('회계년도')[col].transform('mean')\n",
    "    kosdaq_companies_data[f'{col}_전체평균차이'] = overall_avg - kosdaq_companies_data[col]\n",
    "\n",
    "    # 상위 10개 기업 평균과 관련된 열의 이름을 찾기\n",
    "top10_avg_columns = [col for col in kosdaq_companies_data.columns if '_상위10평균' in col]\n",
    "\n",
    "# 상위 10개 기업 평균 관련 열 제거\n",
    "kosdaq_companies_data_cleaned = kosdaq_companies_data.drop(columns=top10_avg_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\성현태\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22660\\916356158.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0msmote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# 결측값이 있는 행 삭제\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# 데이터 분할\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         )\n\u001b[0;32m   1145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1147\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m             _assert_all_finite(\n\u001b[0m\u001b[0;32m    958\u001b[0m                 \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             )\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "#GPT 결측치 처리 코드\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 재무비율만 선택 (수치형 데이터)\n",
    "financial_ratios = kosdaq_companies_data_cleaned.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# 부도기업 레이블링\n",
    "kosdaq_companies_data_cleaned['부도여부'] = kosdaq_companies_data_cleaned['회사명'].isin(kosdaq_delisted_data['회사명']).astype(int)\n",
    "\n",
    "# 독립변수(X)와 종속변수(y) 분리\n",
    "X = financial_ratios\n",
    "y = kosdaq_companies_data_cleaned['부도여부']\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=0)\n",
    "# 결측값이 있는 행 삭제\n",
    "X_resampled, y_resampled = smote.fit_resample(X.dropna(), y[y.index.isin(X.dropna().index)])\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=0)\n",
    "\n",
    "# RandomForest 모델 생성 및 학습\n",
    "rf_classifier = RandomForestClassifier(random_state=0)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 모델 성능 평가\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 특성 중요도 분석 및 시각화\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "features = X_train.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "sorted_idx = feature_importance_df['Importance'].argsort()\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(feature_importances)), feature_importance_df['Importance'][sorted_idx], align='center')\n",
    "plt.yticks(range(len(feature_importances)), [features[i] for i in sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5395\n",
      "Name: 부도여부, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 엑셀 파일 로드\n",
    "kosdaq_delisted_file_path = '상장폐지기업사유(피흡수합병제외).xlsx'\n",
    "kosdaq_delisted_data = pd.read_excel(kosdaq_delisted_file_path)\n",
    "\n",
    "# 데이터셋 B (코스닥 전체 기업) 로드\n",
    "kosdaq_companies_file_path = '111.csv'\n",
    "kosdaq_companies_data = pd.read_csv(kosdaq_companies_file_path, encoding='CP949')\n",
    "\n",
    "# 부도 여부 레이블 생성 (회사명이 존재하면 1, 존재하지 않으면 0)\n",
    "kosdaq_companies_data['부도여부'] = kosdaq_companies_data['회사명'].isin(kosdaq_delisted_data['회사명']).astype(int)\n",
    "\n",
    "# 부도 여부 레이블 확인\n",
    "print(kosdaq_companies_data['부도여부'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\성현태\\AppData\\Local\\Temp\\ipykernel_22660\\1018271360.py:35: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
      "  top10_avg = kosdaq_companies_data.groupby('회계년도')[col].nlargest(10).mean(level=0)\n",
      "C:\\Users\\성현태\\AppData\\Local\\Temp\\ipykernel_22660\\1018271360.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[column] = winsorize(X[column], limits=(lower_percentile, upper_percentile))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The target 'y' needs to have more than 1 class. Got 1 class instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22660\\1018271360.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m# SMOTE 적용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0msmote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;31m# 데이터 분할\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         self.sampling_strategy_ = check_sampling_strategy(\n\u001b[0m\u001b[0;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampling_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\utils\\_validation.py\u001b[0m in \u001b[0;36mcheck_sampling_strategy\u001b[1;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    517\u001b[0m             \u001b[1;34mf\"The target 'y' needs to have more than 1 class. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[1;34mf\"Got {np.unique(y).size} class instead\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The target 'y' needs to have more than 1 class. Got 1 class instead"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# 데이터셋 B (코스닥 전체 기업) 로드\n",
    "kosdaq_companies_file_path = '111.csv'\n",
    "kosdaq_companies_data = pd.read_csv(kosdaq_companies_file_path, encoding='CP949')\n",
    "\n",
    "# 데이터셋 A (상장폐지 기업) 로드 및 전처리\n",
    "kosdaq_delisted_file_path = '상장폐지기업사유(피흡수합병제외).xlsx'\n",
    "kosdaq_delisted_data = pd.read_excel(kosdaq_delisted_file_path)\n",
    "\n",
    "# 데이터셋 A의 결측치 제거 및 이상치 처리\n",
    "numeric_columns = kosdaq_delisted_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numeric_columns:\n",
    "    # 이상치 처리 (1% 범위 Winsorizing)\n",
    "    kosdaq_delisted_data[col] = winsorize(kosdaq_delisted_data[col], limits=[0.01, 0.01])\n",
    "\n",
    "# 데이터셋 B의 재무비율 칼럼 식별 및 회계년도 형식 변환\n",
    "financial_ratios_columns = kosdaq_companies_data.columns.drop(['회사명', '거래소코드', '회계년도'])\n",
    "kosdaq_companies_data['회계년도'] = kosdaq_companies_data['회계년도'].str.split('/').str[0].astype(int)\n",
    "\n",
    "# 각 재무비율에 대해 파생변수 생성\n",
    "for col in financial_ratios_columns:\n",
    "    # 시차 차이 계산\n",
    "    kosdaq_companies_data[f'{col}_시차차이'] = kosdaq_companies_data.groupby('회사명')[col].diff()\n",
    "    # 시차 비율 계산\n",
    "    kosdaq_companies_data[f'{col}_시차비율'] = kosdaq_companies_data.groupby('회사명')[col].pct_change()\n",
    "    # 연도별 상위 10개 기업 평균과의 차이\n",
    "    top10_avg = kosdaq_companies_data.groupby('회계년도')[col].nlargest(10).mean(level=0)\n",
    "    kosdaq_companies_data = kosdaq_companies_data.join(top10_avg, on='회계년도', rsuffix='_상위10평균')\n",
    "    kosdaq_companies_data[f'{col}_상위10차이'] = kosdaq_companies_data[f'{col}_상위10평균'] - kosdaq_companies_data[col]\n",
    "    # 연도별 전체 평균과의 차이\n",
    "    overall_avg = kosdaq_companies_data.groupby('회계년도')[col].transform('mean')\n",
    "    kosdaq_companies_data[f'{col}_전체평균차이'] = overall_avg - kosdaq_companies_data[col]\n",
    "\n",
    "# 상위 10개 기업 평균 관련 열 제거\n",
    "top10_avg_columns = [col for col in kosdaq_companies_data.columns if '_상위10평균' in col]\n",
    "kosdaq_companies_data_cleaned = kosdaq_companies_data.drop(columns=top10_avg_columns)\n",
    "\n",
    "# 재무비율만 선택 (수치형 데이터)\n",
    "financial_ratios = kosdaq_companies_data_cleaned.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# 부도기업 레이블링\n",
    "kosdaq_companies_data_cleaned['부도여부'] = kosdaq_companies_data_cleaned['회사명'].isin(kosdaq_delisted_data['회사명']).astype(int)\n",
    "\n",
    "# 독립변수(X)와 종속변수(y) 분리\n",
    "X = financial_ratios\n",
    "y = kosdaq_companies_data_cleaned['부도여부']\n",
    "\n",
    "# Winsorizing 적용 (하위 1%와 상위 1% 범위에서)\n",
    "lower_percentile = 0.01  # 변경\n",
    "upper_percentile = 0.99  # 변경\n",
    "\n",
    "for column in X.columns:\n",
    "    X[column] = winsorize(X[column], limits=(lower_percentile, upper_percentile))\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=0)\n",
    "X_resampled, y_resampled = smote.fit_resample(X.dropna(), y[y.index.isin(X.dropna().index)])\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=0)\n",
    "\n",
    "# RandomForest 모델 생성 및 학습\n",
    "rf_classifier = RandomForestClassifier(random_state=0)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 모델 성능 평가\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 특성 중요도 분석 및 시각화\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "features = X_train.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "sorted_idx = feature_importance_df['Importance'].argsort()\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(feature_importances)), feature_importance_df['Importance'][sorted_idx], align='center')\n",
    "plt.yticks(range(len(feature_importances)), [features[i] for i in sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24160\\2408724718.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# SMOTE 적용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0msmote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# 데이터 분할\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         )\n\u001b[0;32m   1145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1147\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m             _assert_all_finite(\n\u001b[0m\u001b[0;32m    958\u001b[0m                 \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             )\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nSMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 재무비율만 선택 (수치형 데이터)\n",
    "financial_ratios = kosdaq_companies_data_cleaned.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# 부도기업 레이블링\n",
    "kosdaq_companies_data_cleaned['부도여부'] = kosdaq_companies_data_cleaned['회사명'].isin(kosdaq_delisted_data['회사명']).astype(int)\n",
    "\n",
    "\n",
    "# 독립변수(X)와 종속변수(y) 분리\n",
    "X = financial_ratios\n",
    "y = kosdaq_companies_data_cleaned['부도여부']\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=0)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=0)\n",
    "\n",
    "# RandomForest 모델 생성 및 학습\n",
    "rf_classifier = RandomForestClassifier(random_state=0)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 모델 성능 평가\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 특성 중요도 분석 및 시각화\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "features = X_train.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "sorted_idx = feature_importance_df['Importance'].argsort()\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(feature_importances)), feature_importance_df['Importance'][sorted_idx], align='center')\n",
    "plt.yticks(range(len(feature_importances)), [features[i] for i in sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>거래소코드</th>\n",
       "      <th>회계년도</th>\n",
       "      <th>매출액증가율(IFRS)</th>\n",
       "      <th>총자본증가율(IFRS)</th>\n",
       "      <th>매출액순이익률(IFRS)</th>\n",
       "      <th>총자본정상영업이익률(IFRS)</th>\n",
       "      <th>CASH FLOW 대 부채비율(IFRS)</th>\n",
       "      <th>CASH FLOW 대 총자본비율(IFRS)</th>\n",
       "      <th>총자본회전률(IFRS)</th>\n",
       "      <th>...</th>\n",
       "      <th>자기자본회전률(IFRS)_상위10차이</th>\n",
       "      <th>자기자본회전률(IFRS)_전체평균차이</th>\n",
       "      <th>총자본투자효율(IFRS)_시차차이</th>\n",
       "      <th>총자본투자효율(IFRS)_시차비율</th>\n",
       "      <th>총자본투자효율(IFRS)_상위10차이</th>\n",
       "      <th>총자본투자효율(IFRS)_전체평균차이</th>\n",
       "      <th>설비투자효율(IFRS)_시차차이</th>\n",
       "      <th>설비투자효율(IFRS)_시차비율</th>\n",
       "      <th>설비투자효율(IFRS)_상위10차이</th>\n",
       "      <th>설비투자효율(IFRS)_전체평균차이</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2010</td>\n",
       "      <td>11.86</td>\n",
       "      <td>17.25</td>\n",
       "      <td>-61.19</td>\n",
       "      <td>-30.38</td>\n",
       "      <td>-69.69</td>\n",
       "      <td>-21.79</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>12.579</td>\n",
       "      <td>1.047123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.521</td>\n",
       "      <td>6.615046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6390.425</td>\n",
       "      <td>-594.196439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2011</td>\n",
       "      <td>56.40</td>\n",
       "      <td>2.89</td>\n",
       "      <td>-7.12</td>\n",
       "      <td>2.63</td>\n",
       "      <td>-45.76</td>\n",
       "      <td>-15.38</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>13.754</td>\n",
       "      <td>0.906655</td>\n",
       "      <td>10.34</td>\n",
       "      <td>3.469799</td>\n",
       "      <td>71.300</td>\n",
       "      <td>-1.978467</td>\n",
       "      <td>30.37</td>\n",
       "      <td>3.923773</td>\n",
       "      <td>10378.596</td>\n",
       "      <td>-560.486260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2012</td>\n",
       "      <td>-8.43</td>\n",
       "      <td>106.87</td>\n",
       "      <td>-42.40</td>\n",
       "      <td>-9.57</td>\n",
       "      <td>-7.76</td>\n",
       "      <td>-3.46</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>14.060</td>\n",
       "      <td>1.165377</td>\n",
       "      <td>-13.47</td>\n",
       "      <td>-1.011261</td>\n",
       "      <td>85.764</td>\n",
       "      <td>15.054752</td>\n",
       "      <td>-39.06</td>\n",
       "      <td>-1.024928</td>\n",
       "      <td>25175.129</td>\n",
       "      <td>374.511887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2013</td>\n",
       "      <td>25.02</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.46</td>\n",
       "      <td>-38.65</td>\n",
       "      <td>-4.78</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>11.718</td>\n",
       "      <td>1.234492</td>\n",
       "      <td>12.57</td>\n",
       "      <td>-83.800000</td>\n",
       "      <td>59.064</td>\n",
       "      <td>2.728453</td>\n",
       "      <td>78.39</td>\n",
       "      <td>-82.515789</td>\n",
       "      <td>121329.169</td>\n",
       "      <td>1425.776640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(주)CMG제약</td>\n",
       "      <td>58820</td>\n",
       "      <td>2014</td>\n",
       "      <td>11.96</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-17.44</td>\n",
       "      <td>-2.72</td>\n",
       "      <td>0.40</td>\n",
       "      <td>...</td>\n",
       "      <td>10.518</td>\n",
       "      <td>1.158322</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.021739</td>\n",
       "      <td>79.753</td>\n",
       "      <td>3.850304</td>\n",
       "      <td>-39.62</td>\n",
       "      <td>-0.511622</td>\n",
       "      <td>3357420.681</td>\n",
       "      <td>37878.647669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        회사명  거래소코드  회계년도  매출액증가율(IFRS)  총자본증가율(IFRS)  매출액순이익률(IFRS)  \\\n",
       "0  (주)CMG제약  58820  2010         11.86         17.25         -61.19   \n",
       "1  (주)CMG제약  58820  2011         56.40          2.89          -7.12   \n",
       "2  (주)CMG제약  58820  2012         -8.43        106.87         -42.40   \n",
       "3  (주)CMG제약  58820  2013         25.02         -1.80           1.65   \n",
       "4  (주)CMG제약  58820  2014         11.96          3.87           0.75   \n",
       "\n",
       "   총자본정상영업이익률(IFRS)  CASH FLOW 대 부채비율(IFRS)  CASH FLOW 대 총자본비율(IFRS)  \\\n",
       "0            -30.38                  -69.69                   -21.79   \n",
       "1              2.63                  -45.76                   -15.38   \n",
       "2             -9.57                   -7.76                    -3.46   \n",
       "3              1.46                  -38.65                    -4.78   \n",
       "4              0.78                  -17.44                    -2.72   \n",
       "\n",
       "   총자본회전률(IFRS)  ...  자기자본회전률(IFRS)_상위10차이  자기자본회전률(IFRS)_전체평균차이  \\\n",
       "0          0.46  ...                12.579              1.047123   \n",
       "1          0.65  ...                13.754              0.906655   \n",
       "2          0.38  ...                14.060              1.165377   \n",
       "3          0.36  ...                11.718              1.234492   \n",
       "4          0.40  ...                10.518              1.158322   \n",
       "\n",
       "   총자본투자효율(IFRS)_시차차이  총자본투자효율(IFRS)_시차비율  총자본투자효율(IFRS)_상위10차이  \\\n",
       "0                 NaN                 NaN                70.521   \n",
       "1               10.34            3.469799                71.300   \n",
       "2              -13.47           -1.011261                85.764   \n",
       "3               12.57          -83.800000                59.064   \n",
       "4               -0.27           -0.021739                79.753   \n",
       "\n",
       "   총자본투자효율(IFRS)_전체평균차이  설비투자효율(IFRS)_시차차이  설비투자효율(IFRS)_시차비율  \\\n",
       "0              6.615046                NaN                NaN   \n",
       "1             -1.978467              30.37           3.923773   \n",
       "2             15.054752             -39.06          -1.024928   \n",
       "3              2.728453              78.39         -82.515789   \n",
       "4              3.850304             -39.62          -0.511622   \n",
       "\n",
       "   설비투자효율(IFRS)_상위10차이  설비투자효율(IFRS)_전체평균차이  \n",
       "0             6390.425          -594.196439  \n",
       "1            10378.596          -560.486260  \n",
       "2            25175.129           374.511887  \n",
       "3           121329.169          1425.776640  \n",
       "4          3357420.681         37878.647669  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kosdaq_companies_data_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\성현태\\AppData\\Local\\Temp\\ipykernel_11624\\520112913.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  kosdaq_companies_data_clean['부도여부'] = kosdaq_companies_data_clean['회사명'].isin(kosdaq_delisted_data['회사명']).astype(int)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The target 'y' needs to have more than 1 class. Got 1 class instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11624\\520112913.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# SMOTE 적용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0msmote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# 데이터 분할\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         self.sampling_strategy_ = check_sampling_strategy(\n\u001b[0m\u001b[0;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampling_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imblearn\\utils\\_validation.py\u001b[0m in \u001b[0;36mcheck_sampling_strategy\u001b[1;34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    517\u001b[0m             \u001b[1;34mf\"The target 'y' needs to have more than 1 class. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[1;34mf\"Got {np.unique(y).size} class instead\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The target 'y' needs to have more than 1 class. Got 1 class instead"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터셋 B (코스닥 전체 기업) 및 데이터셋 A (상장폐지 기업) 로드\n",
    "kosdaq_companies_file_path = '111.csv'\n",
    "kosdaq_companies_data = pd.read_csv(kosdaq_companies_file_path, encoding='CP949')\n",
    "kosdaq_delisted_file_path = '상장폐지기업사유(피흡수합병제외).xlsx'\n",
    "kosdaq_delisted_data = pd.read_excel(kosdaq_delisted_file_path)\n",
    "\n",
    "# 결측치 제거\n",
    "kosdaq_companies_data_clean = kosdaq_companies_data.dropna()\n",
    "\n",
    "# 재무비율만 선택 (수치형 데이터)\n",
    "financial_ratios = kosdaq_companies_data_clean.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# 부도기업 레이블링\n",
    "kosdaq_companies_data_clean['부도여부'] = kosdaq_companies_data_clean['회사명'].isin(kosdaq_delisted_data['회사명']).astype(int)\n",
    "\n",
    "# 독립변수(X)와 종속변수(y) 분리\n",
    "X = financial_ratios\n",
    "y = kosdaq_companies_data_clean['부도여부']\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=0)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=0)\n",
    "\n",
    "# RandomForest 모델 생성 및 학습\n",
    "rf_classifier = RandomForestClassifier(random_state=0)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 모델 성능 평가\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "classification_report_result = classification_report(y_test, y_pred)\n",
    "confusion_matrix_result = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 특성 중요도 분석 및 시각화\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "features = X_train.columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
    "sorted_idx = feature_importance_df['Importance'].argsort()\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(feature_importances)), feature_importance_df['Importance'][sorted_idx], align='center')\n",
    "plt.yticks(range(len(feature_importances)), [features[i] for i in sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
